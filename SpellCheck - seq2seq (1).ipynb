{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/piyush0511/SpellChecker-AutoCorrect/blob/main/SpellCheck%20-%20seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hVhAsFY0fPE"
   },
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4C-rZbxU0fPG",
    "outputId": "8a13043e-7c30-4bcd-f641-d86575eb2743"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "# if device_name != '/device:GPU:0':\n",
    "#   raise SystemError('GPU device not found')\n",
    "# print('Found GPU at: {}'.format(device_name))\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = r'C:\\Users\\ASUS\\Desktop\\Naveen\\SFU\\Sem_2\\Special topics\\Project\\datasets\\beers\\clean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>style</th>\n",
       "      <th>ounces</th>\n",
       "      <th>abv</th>\n",
       "      <th>ibu</th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1436</td>\n",
       "      <td>Pub Beer</td>\n",
       "      <td>American Pale Lager</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408</td>\n",
       "      <td>10 Barrel Brewing Company</td>\n",
       "      <td>Bend</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2265</td>\n",
       "      <td>Devil's Cup</td>\n",
       "      <td>American Pale Ale (APA)</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177</td>\n",
       "      <td>18th Street Brewery</td>\n",
       "      <td>Gary</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2264</td>\n",
       "      <td>Rise of the Phoenix</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177</td>\n",
       "      <td>18th Street Brewery</td>\n",
       "      <td>Gary</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2263</td>\n",
       "      <td>Sinister</td>\n",
       "      <td>American Double / Imperial IPA</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177</td>\n",
       "      <td>18th Street Brewery</td>\n",
       "      <td>Gary</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2262</td>\n",
       "      <td>Sex and Candy</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177</td>\n",
       "      <td>18th Street Brewery</td>\n",
       "      <td>Gary</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2405</th>\n",
       "      <td>928</td>\n",
       "      <td>Belgorado</td>\n",
       "      <td>Belgian IPA</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.067</td>\n",
       "      <td>45.0</td>\n",
       "      <td>424</td>\n",
       "      <td>Wynkoop Brewing Company</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>807</td>\n",
       "      <td>Rail Yard Ale</td>\n",
       "      <td>American Amber / Red Ale</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>424</td>\n",
       "      <td>Wynkoop Brewing Company</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407</th>\n",
       "      <td>620</td>\n",
       "      <td>B3K Black Lager</td>\n",
       "      <td>Schwarzbier</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>424</td>\n",
       "      <td>Wynkoop Brewing Company</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>145</td>\n",
       "      <td>Silverback Pale Ale</td>\n",
       "      <td>American Pale Ale (APA)</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.055</td>\n",
       "      <td>40.0</td>\n",
       "      <td>424</td>\n",
       "      <td>Wynkoop Brewing Company</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>84</td>\n",
       "      <td>Rail Yard Ale (2009)</td>\n",
       "      <td>American Amber / Red Ale</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>424</td>\n",
       "      <td>Wynkoop Brewing Company</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2410 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id             beer_name                           style  ounces  \\\n",
       "0     1436              Pub Beer             American Pale Lager    12.0   \n",
       "1     2265           Devil's Cup         American Pale Ale (APA)    12.0   \n",
       "2     2264   Rise of the Phoenix                    American IPA    12.0   \n",
       "3     2263              Sinister  American Double / Imperial IPA    12.0   \n",
       "4     2262         Sex and Candy                    American IPA    12.0   \n",
       "...    ...                   ...                             ...     ...   \n",
       "2405   928             Belgorado                     Belgian IPA    12.0   \n",
       "2406   807         Rail Yard Ale        American Amber / Red Ale    12.0   \n",
       "2407   620       B3K Black Lager                     Schwarzbier    12.0   \n",
       "2408   145   Silverback Pale Ale         American Pale Ale (APA)    12.0   \n",
       "2409    84  Rail Yard Ale (2009)        American Amber / Red Ale    12.0   \n",
       "\n",
       "        abv   ibu brewery_id               brewery_name    city state  \n",
       "0     0.050   NaN        408  10 Barrel Brewing Company    Bend    OR  \n",
       "1     0.066   NaN        177        18th Street Brewery    Gary    IN  \n",
       "2     0.071   NaN        177        18th Street Brewery    Gary    IN  \n",
       "3     0.090   NaN        177        18th Street Brewery    Gary    IN  \n",
       "4     0.075   NaN        177        18th Street Brewery    Gary    IN  \n",
       "...     ...   ...        ...                        ...     ...   ...  \n",
       "2405  0.067  45.0        424    Wynkoop Brewing Company  Denver    CO  \n",
       "2406  0.052   NaN        424    Wynkoop Brewing Company  Denver    CO  \n",
       "2407  0.055   NaN        424    Wynkoop Brewing Company  Denver    CO  \n",
       "2408  0.055  40.0        424    Wynkoop Brewing Company  Denver    CO  \n",
       "2409  0.052   NaN        424    Wynkoop Brewing Company  Denver    CO  \n",
       "\n",
       "[2410 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'file_path.xls' with the path to your XLS file\n",
    "# file_path = 'file_path.xls'\n",
    "\n",
    "# Read the XLS file into a Pandas DataFrame\n",
    "df = pd.read_csv(loc)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDlCOtCa0fPJ"
   },
   "source": [
    "## Download the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCNYZFoX0fPL",
    "outputId": "96c9fb68-950a-4158-fd9d-6c07a464e6d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  2 7756k    2  219k    0     0   662k      0  0:00:11 --:--:--  0:00:11  662k\n",
      " 19 7756k   19 1524k    0     0  1153k      0  0:00:06  0:00:01  0:00:05 1153k\n",
      " 37 7756k   37 2938k    0     0  1266k      0  0:00:06  0:00:02  0:00:04 1266k\n",
      " 55 7756k   55 4279k    0     0  1289k      0  0:00:06  0:00:03  0:00:03 1289k\n",
      " 72 7756k   72 5625k    0     0  1299k      0  0:00:05  0:00:04  0:00:01 1299k\n",
      " 90 7756k   90 6986k    0     0  1311k      0  0:00:05  0:00:05 --:--:-- 1354k\n",
      "100 7756k  100 7756k    0     0  1307k      0  0:00:05  0:00:05 --:--:-- 1351k\n"
     ]
    }
   ],
   "source": [
    "!curl -O http://www.manythings.org/anki/fra-eng.zip\n",
    "# !unzip fra-eng.zip\n",
    "with zipfile.ZipFile('fra-eng.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecuyvq-l0fPM"
   },
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QfVbN9f9wtLS"
   },
   "outputs": [],
   "source": [
    "num_samples = 120000   # Number of samples to train on.\n",
    "data_path = \"fra.txt\"  # Path to the data txt file on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IwwS5dJF0fPO"
   },
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 128  # Latent dimensionality of the encoding space.\n",
    "output_dim = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGq8DaBm0fPQ"
   },
   "source": [
    "## Prepare the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['beer_name'].to_csv('output.csv', index=False, header=True)\n",
    "df['beer_name'] = df['beer_name'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['beer_name'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_samples, len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Vectorize the data.\n",
    "# input_texts = []\n",
    "# target_texts = []\n",
    "# input_ =[]\n",
    "# tar_ =[]\n",
    "# input_characters = set()\n",
    "# target_characters = set()\n",
    "# # with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "# #     lines = f.read().split(\"\\n\")\n",
    "\n",
    "# # for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "# for index, row in df.iterrows():\n",
    "#   for _ in range(5):\n",
    "# #       input_text, target_text, _ = line.split(\"\\t\")\n",
    "#       input_text = row['beer_name']\n",
    "# #       print('//',input_text.lower())\n",
    "#       input_text = input_text.lower()\n",
    "# #       print(input_text,target_text)\n",
    "#       input_text = re.sub(r'[^a-zA-Z ]+', '', input_text)\n",
    "#       target_text = \"\\t\" + input_text + \"\\n\"\n",
    "#       for i in range(np.random.choice(np.arange(0, 2), p=[0.1, 0.9])):\n",
    "            \n",
    "#           if len(input_text) == 0:\n",
    "#               print('$$$',list(input_text))\n",
    "#               input_text = ' '\n",
    "#           else:\n",
    "#               input_text = input_text.replace(random.choice(list(input_text)),random.choice(string.ascii_letters))\n",
    "\n",
    "    \n",
    "#       input_texts.append(input_text.lower())\n",
    "#       print(target_text)\n",
    "#       target_texts.append(target_text)\n",
    "#       for char in input_text.lower():\n",
    "#           if char not in input_characters:\n",
    "#               input_characters.add(char)\n",
    "#       for char in target_text:\n",
    "#           if char not in target_characters:\n",
    "#               target_characters.add(char)\n",
    "\n",
    "\n",
    "# input_characters = sorted(list(input_characters))\n",
    "# target_characters = sorted(list(target_characters))\n",
    "# num_encoder_tokens = len(input_characters)\n",
    "# num_decoder_tokens = len(target_characters)\n",
    "# max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "# max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "# print(\"Number of samples:\", len(input_texts))\n",
    "# print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "# print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "# print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "# print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
    "\n",
    "# input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "# target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "# encoder_input_data = np.zeros(\n",
    "#     (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    "# )\n",
    "# decoder_input_data = np.zeros(\n",
    "#     (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    "# )\n",
    "# decoder_target_data = np.zeros(\n",
    "#     (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    "# )\n",
    "\n",
    "# for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "#     for t, char in enumerate(input_text):\n",
    "#         encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "#     encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "#     for t, char in enumerate(target_text):\n",
    "#         # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "#         decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "#         if t > 0:\n",
    "#             # decoder_target_data will be ahead by one timestep\n",
    "#             # and will not include the start character.\n",
    "#             decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "#     decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "#     decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9QynAASs0fPR",
    "outputId": "14c0f75f-456b-4536-a392-d8392b81906c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 600000\n",
      "Number of unique input tokens: 27\n",
      "Number of unique output tokens: 29\n",
      "Max sequence length for inputs: 28\n",
      "Max sequence length for outputs: 30\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_ =[]\n",
    "tar_ =[]\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "  for _ in range(5):\n",
    "      input_text, target_text, _ = line.split(\"\\t\")\n",
    "      input_text = input_text.lower()\n",
    "      input_text = re.sub(r'[^a-zA-Z ]+', '', input_text)\n",
    "      target_text = \"\\t\" + input_text + \"\\n\"\n",
    "      for i in range(np.random.choice(np.arange(0, 2), p=[0.1, 0.9])):\n",
    "\n",
    "          input_text = input_text.replace(random.choice(list(input_text)),random.choice(string.ascii_letters))\n",
    "\n",
    "      input_texts.append(input_text.lower())\n",
    "      target_texts.append(target_text)\n",
    "      for char in input_text.lower():\n",
    "          if char not in input_characters:\n",
    "              input_characters.add(char)\n",
    "      for char in target_text:\n",
    "          if char not in target_characters:\n",
    "              target_characters.add(char)\n",
    "\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print(\"Number of samples:\", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
    "\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\t',\n",
       " '\\n',\n",
       " ' ',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "usVvqv479t6-",
    "outputId": "00abcd6e-3a61-467d-b3c1-f35413b971b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " 'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BR-45q9l0fPS"
   },
   "source": [
    "## Build the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "eqcJXSpf0fPW"
   },
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "encoder = keras.layers.LSTM(latent_dim, return_state=True, dropout=0.4)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "011HNgPC0fPY"
   },
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "l1QQlgUGePD0"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1iR-Vda0fPZ",
    "outputId": "08ee65ec-e442-49f4-a07e-0e7f2ff64a47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7500/7500 [==============================] - 411s 54ms/step - loss: 1.2185 - accuracy: 0.6415 - val_loss: 1.1043 - val_accuracy: 0.6707\n",
      "Epoch 2/3\n",
      "7500/7500 [==============================] - 385s 51ms/step - loss: 0.8713 - accuracy: 0.7443 - val_loss: 0.9714 - val_accuracy: 0.7113\n",
      "Epoch 3/3\n",
      "7500/7500 [==============================] - 388s 52ms/step - loss: 0.7737 - accuracy: 0.7742 - val_loss: 0.9103 - val_accuracy: 0.7296\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=3,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "# Save model\n",
    "model.save(\"auto.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zob6hqbcQ4mb",
    "outputId": "f3bfcd10-5c33-424c-aa7b-70908a0d2253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 27)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 29)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 128), (None, 79872       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 128),  80896       input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 29)     3741        lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 164,509\n",
      "Trainable params: 164,509\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "id": "DhiikUDdSzdR",
    "outputId": "71be07cf-ffa1-4c1d-e4ef-e21639621123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"model.png\",\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2E4PYq60fPZ"
   },
   "source": [
    "## Run inference (sampling)\n",
    "\n",
    "1. encode input and retrieve initial decoder state\n",
    "2. run one step of decoder with this initial state\n",
    "and a \"start of sequence\" token as target.\n",
    "Output will be the next target token.\n",
    "3. Repeat with the current target token and current states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "tuvNA11W0fPa"
   },
   "outputs": [],
   "source": [
    "# Define sampling models\n",
    "# Restore the model and construct the encoder and decoder.\n",
    "#model = keras.models.load_model(\"s2s\")\n",
    "\n",
    "encoder_inputs = model.input[0]  # input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]  # input_2\n",
    "decoder_state_input_h = keras.Input(shape=(latent_dim,), name=\"input_3\")\n",
    "decoder_state_input_c = keras.Input(shape=(latent_dim,), name=\"input_4\")\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jpizE_20fPb"
   },
   "source": [
    "You can now generate decoded sentences as such:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSV5ZcS0Gg3p",
    "outputId": "2a33e0b4-ab39-4199-9fcb-ca7107bad43c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you must beel anower\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_text = \"ygu mqst leave now\"\n",
    "\n",
    "encoder_test_data = np.zeros(\n",
    "    (1, max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\n",
    "\n",
    "for t, char in enumerate(test_text):\n",
    "    encoder_test_data[0, t, input_token_index[char]] = 1.0\n",
    "\n",
    "decoded_sentence = decode_sequence(encoder_test_data)\n",
    "print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dMTz-Quy0fPb",
    "outputId": "c944d966-b7c1-4e71-8b20-02c6501c621c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:05<00:00,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "out = pd.DataFrame(columns = [\"input\", \"decoded\", \"target\"])\n",
    "tt = 0\n",
    "for seq_index in tqdm(range(57300, 57400)):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    out.loc[len(out.index)] = [input_texts[seq_index], decoded_sentence, target_texts[seq_index]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "xM4qGjIJ4mr-",
    "outputId": "8feed852-7ae9-4c88-a6f6-c95a89d6ab50"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>decoded</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>i like oranves</td>\n",
       "      <td>i like bestens\\n</td>\n",
       "      <td>\\ti like oranges\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>iklikekoranges</td>\n",
       "      <td>i like busties\\n</td>\n",
       "      <td>\\ti like oranges\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>i like oranges</td>\n",
       "      <td>i like bustens\\n</td>\n",
       "      <td>\\ti like oranges\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>y lyke oranges</td>\n",
       "      <td>i love bustens\\n</td>\n",
       "      <td>\\ti like oranges\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>illikeloranges</td>\n",
       "      <td>i like busties\\n</td>\n",
       "      <td>\\ti like oranges\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>i like oysters</td>\n",
       "      <td>i like to seet\\n</td>\n",
       "      <td>\\ti like oysters\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>ielikeeoysters</td>\n",
       "      <td>i like to seet\\n</td>\n",
       "      <td>\\ti like oysters\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>i liky oystyrs</td>\n",
       "      <td>i like you say\\n</td>\n",
       "      <td>\\ti like oysters\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>i vike oysters</td>\n",
       "      <td>i have to seet\\n</td>\n",
       "      <td>\\ti like oysters\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>inlikenoysters</td>\n",
       "      <td>i like to seet\\n</td>\n",
       "      <td>\\ti like oysters\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>i like pibnibs</td>\n",
       "      <td>i like be ines\\n</td>\n",
       "      <td>\\ti like picnics\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>inlikenpicnics</td>\n",
       "      <td>i like soncint\\n</td>\n",
       "      <td>\\ti like picnics\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>i likx picnics</td>\n",
       "      <td>i like pantins\\n</td>\n",
       "      <td>\\ti like picnics\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>e leke pecnecs</td>\n",
       "      <td>i love precent\\n</td>\n",
       "      <td>\\ti like picnics\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>iklikekpicnics</td>\n",
       "      <td>i like pancint\\n</td>\n",
       "      <td>\\ti like picnics\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>j ljke pjcnjcs</td>\n",
       "      <td>i love pastice\\n</td>\n",
       "      <td>\\ti like picnics\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>i like pipnips</td>\n",
       "      <td>i like passins\\n</td>\n",
       "      <td>\\ti like picnics\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>l llke plcnlcs</td>\n",
       "      <td>i love placies\\n</td>\n",
       "      <td>\\ti like picnics\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>x lxke pxcnxcs</td>\n",
       "      <td>i like pancint\\n</td>\n",
       "      <td>\\ti like picnics\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>i liks picnics</td>\n",
       "      <td>i like sistins\\n</td>\n",
       "      <td>\\ti like picnics\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             input           decoded              target\n",
       "80  i like oranves  i like bestens\\n  \\ti like oranges\\n\n",
       "81  iklikekoranges  i like busties\\n  \\ti like oranges\\n\n",
       "82  i like oranges  i like bustens\\n  \\ti like oranges\\n\n",
       "83  y lyke oranges  i love bustens\\n  \\ti like oranges\\n\n",
       "84  illikeloranges  i like busties\\n  \\ti like oranges\\n\n",
       "85  i like oysters  i like to seet\\n  \\ti like oysters\\n\n",
       "86  ielikeeoysters  i like to seet\\n  \\ti like oysters\\n\n",
       "87  i liky oystyrs  i like you say\\n  \\ti like oysters\\n\n",
       "88  i vike oysters  i have to seet\\n  \\ti like oysters\\n\n",
       "89  inlikenoysters  i like to seet\\n  \\ti like oysters\\n\n",
       "90  i like pibnibs  i like be ines\\n  \\ti like picnics\\n\n",
       "91  inlikenpicnics  i like soncint\\n  \\ti like picnics\\n\n",
       "92  i likx picnics  i like pantins\\n  \\ti like picnics\\n\n",
       "93  e leke pecnecs  i love precent\\n  \\ti like picnics\\n\n",
       "94  iklikekpicnics  i like pancint\\n  \\ti like picnics\\n\n",
       "95  j ljke pjcnjcs  i love pastice\\n  \\ti like picnics\\n\n",
       "96  i like pipnips  i like passins\\n  \\ti like picnics\\n\n",
       "97  l llke plcnlcs  i love placies\\n  \\ti like picnics\\n\n",
       "98  x lxke pxcnxcs  i like pancint\\n  \\ti like picnics\\n\n",
       "99  i liks picnics  i like sistins\\n  \\ti like picnics\\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.tail(20)\n",
    "#np.shape(input_seq)\n",
    "#tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>decoded</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i tike btondes</td>\n",
       "      <td>i like bo sees\\n</td>\n",
       "      <td>\\ti like blondes\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i lize blondes</td>\n",
       "      <td>i like blonens\\n</td>\n",
       "      <td>\\ti like blondes\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i like blondes</td>\n",
       "      <td>i like blonens\\n</td>\n",
       "      <td>\\ti like blondes\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i like blondes</td>\n",
       "      <td>i like blonens\\n</td>\n",
       "      <td>\\ti like blondes\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i like blondes</td>\n",
       "      <td>i like blonens\\n</td>\n",
       "      <td>\\ti like blondes\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>j ljke pjcnjcs</td>\n",
       "      <td>i love pastice\\n</td>\n",
       "      <td>\\ti like picnics\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>i like pipnips</td>\n",
       "      <td>i like passins\\n</td>\n",
       "      <td>\\ti like picnics\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>l llke plcnlcs</td>\n",
       "      <td>i love placies\\n</td>\n",
       "      <td>\\ti like picnics\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>x lxke pxcnxcs</td>\n",
       "      <td>i like pancint\\n</td>\n",
       "      <td>\\ti like picnics\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>i liks picnics</td>\n",
       "      <td>i like sistins\\n</td>\n",
       "      <td>\\ti like picnics\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             input           decoded              target\n",
       "0   i tike btondes  i like bo sees\\n  \\ti like blondes\\n\n",
       "1   i lize blondes  i like blonens\\n  \\ti like blondes\\n\n",
       "2   i like blondes  i like blonens\\n  \\ti like blondes\\n\n",
       "3   i like blondes  i like blonens\\n  \\ti like blondes\\n\n",
       "4   i like blondes  i like blonens\\n  \\ti like blondes\\n\n",
       "..             ...               ...                 ...\n",
       "95  j ljke pjcnjcs  i love pastice\\n  \\ti like picnics\\n\n",
       "96  i like pipnips  i like passins\\n  \\ti like picnics\\n\n",
       "97  l llke plcnlcs  i love placies\\n  \\ti like picnics\\n\n",
       "98  x lxke pxcnxcs  i like pancint\\n  \\ti like picnics\\n\n",
       "99  i liks picnics  i like sistins\\n  \\ti like picnics\\n\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "p_tcjp4t5RR6"
   },
   "outputs": [],
   "source": [
    "f = open('var.pkl','wb')\n",
    "jj = {\"input_token_index\":input_token_index, \"target_token_index\":target_token_index, \"num_decoder_tokens\": num_decoder_tokens, \"max_encoder_seq_length\":max_encoder_seq_length, \"num_encoder_tokens\": num_encoder_tokens}\n",
    "pickle.dump(jj, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ec4TGktFEJ4W"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "lstm_seq2seq_Spellcheck_Sentence",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
